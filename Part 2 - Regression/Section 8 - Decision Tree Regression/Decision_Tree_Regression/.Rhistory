print("Hello world")
source('C:/Users/Asanka/Desktop/Udmy/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 6 - Polynomial Regression/data_preprocessing_template.R')
source('C:/Users/Asanka/Desktop/Udmy/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 6 - Polynomial Regression/data_preprocessing_template.R')
dataset = read.csv('Position_Salaries.csv')
setwd("C:/Users/Asanka/Desktop/Udmy/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 6 - Polynomial Regression")
dataset = read.csv('Position_Salaries.csv')
View(dataset)
View(dataset)
View(dataset)
View(dataset)
View(dataset)
View(dataset)
dataset = read.csv('Position_Salaries.csv')
dataset=dataset[2:3]
View(dataset)
View(dataset)
install.packages(c("scales", "tibble"))
lin_Reg=lm(formula = Salary~.
,data=dataset)
dataset$Level2=dataset$Level^2
View(dataset)
dataset$Level2=dataset$Level^2
dataset$Level3 = dataset$Level^3
dataset$Level4 = dataset$Level^4
poly_Reg=lm(formula = Salary~. ,
data=dataset )
poly_Reg
summary(poly_Reg)
install.packages('ggplot2')
library(ggplot2)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(lin_reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
ylab('Salary')
lin_Reg=lm(formula = Salary~.
,data=dataset)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(lin_Reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
ylab('Salary')
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level2, y = predict(lin_Reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
ylab('Salary')
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(lin_Reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
ylab('Salary')
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Leveldataset$Level, y = predict(poly_Reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
ylab('Salary')
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(poly_Reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
ylab('Salary')
dataset = read.csv('Position_Salaries.csv')
dataset=dataset[2:3]
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(lin_Reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
ylab('Salary')
#Fitting Linear Regression to the dataset
lin_Reg=lm(formula = Salary~.
,data=dataset)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(lin_Reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
ylab('Salary')
dataset$Level2=dataset$Level^2
dataset$Level3 = dataset$Level^3
dataset$Level4 = dataset$Level^4
poly_Reg=lm(formula = Salary~. ,
data=dataset )
dataset$Level2=dataset$Level^2
dataset$Level3 = dataset$Level^3
dataset$Level4 = dataset$Level^4
poly_Reg=lm(formula = Salary~. ,
data=dataset )
# Visualising the Linear Regression results
install.packages('ggplot2')
library(ggplot2)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(poly_Reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
ylab('Salary')
install.packages("ggplot2")
# Visualising the Linear Regression results
#  install.packages('ggplot2')
# library(ggplot2)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(poly_Reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
dataset$Level2=dataset$Level^2
dataset$Level3 = dataset$Level^3
dataset$Level4 = dataset$Level^4
poly_Reg=lm(formula = Salary~. ,
data=dataset )
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(poly_Reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
ylab('Salary')
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level2, y = predict(poly_Reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
ylab('Salary')
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(poly_Reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
ylab('Salary')
dataset$Level2=dataset$Level^2
dataset$Level3 = dataset$Level^3
dataset$Level4 = dataset$Level^4
dataset$Level4 = dataset$Level^5
poly_Reg=lm(formula = Salary~. ,
data=dataset )
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(poly_Reg, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
ylab('Salary')
source('C:/Users/Asanka/Desktop/Udmy/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 7 - Support Vector Regression (SVR)/regression_template.R')
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[2:3]
View(dataset)
View(dataset)
install.packages('e1071')
library(e1071)
regressor=svm(formula=Salary~. ,
data=dataset ,type='eps-regression' )
# SVR
# Importing the dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[2:3]
# Splitting the dataset into the Training set and Test set
# # install.packages('caTools')
# library(caTools)
# set.seed(123)
# split = sample.split(dataset$Salary, SplitRatio = 2/3)
# training_set = subset(dataset, split == TRUE)
# test_set = subset(dataset, split == FALSE)
# Feature Scaling
# training_set = scale(training_set)
# test_set = scale(test_set)
# Fitting the SVR Model to the dataset
# Create your regressor here
#fitting the SVR to dataset
install.packages('e1071')
library(e1071)
regressor=svm(formula=Salary~. ,
data=dataset ,type='eps-regression' )#type=eps -> for regression
install.packages("e1071")
View(dataset)
View(dataset)
y_pred = predict(regressor, data.frame(Level = 6.5))
# SVR
# Importing the dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[2:3]
#fitting the SVR to dataset
#install.packages('e1071')
library(e1071)
regressor=svm(formula=Salary~. ,
data=dataset ,type='eps-regression' )#type=eps -> for regression
# Predicting a new result
y_pred = predict(regressor, data.frame(Level = 6.5))
# install.packages('ggplot2')
library(ggplot2)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(regressor, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Regression Model)') +
xlab('Level') +
ylab('Salary')
# Visualising the Regression Model results (for higher resolution and smoother curve)
# install.packages('ggplot2')
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Regression Model)') +
xlab('Level') +
ylab('Salary')
# Data Preprocessing Template
# Importing the dataset
dataset = read.csv('50_Startups.csv')
# Encoding categorical data //because linear regression needs numbers
dataset$State = factor(dataset$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1, 2, 3))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Profit, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling //- no need replaces by a function we use
#Fitting multiple Linear Regression to the training set
regressor=lm(formula = Profit~. ,data=training_set)#lm(relationship between dependent and independent Variables)
#Since R & D spent is the highly strongly predictor other variables are not much useful
#regressor=lm(formula = Profit~R.D.Spend ,data=training_set)
#predictiing the test set results
y_pred=predict(regressor,newdata=test_set)
#making optimal model using ~ BACKWORD ELIMINATION ~
regressor=lm(formula = Profit~R.D.Spend+Administration+Marketing.Spend+State ,data=training_set)
y_pred=predict(regressor,newdata=dataset)
summary(regressor)
#making optimal model using ~ BACKWORD ELIMINATION ~
regressor=lm(formula = Profit~R.D.Spend+Administration+Marketing.Spend ,data=training_set)#Remove state since p=0.9xx
y_pred=predict(regressor,newdata=dataset)
summary(regressor)
#making optimal model using ~ BACKWORD ELIMINATION ~
regressor=lm(formula = Profit~R.D.Spend+Marketing.Spend,data=training_set)#Remove Administration since p>SL
y_pred=predict(regressor,newdata=dataset)
summary(regressor)
#making optimal model using ~ BACKWORD ELIMINATION ~
regressor=lm(formula = Profit~R.D.Spend,data=training_set)#Remove Marketing.Spend since p>SL
y_pred=predict(regressor,newdata=dataset)
summary(regressor)#making optimal model using ~ BACKWORD ELIMINATION ~
regressor=lm(formula = Profit~R.D.Spend+Marketing.Spend,data=training_set)#Since marketing.Spend have no big difference,keep it
y_pred=predict(regressor,newdata=dataset)
summary(regressor)
summary(regressor)
regressor=lm(formula = Profit~R.D.Spend+Administration+Marketing.Spend+State ,data=training_set)
y_pred=predict(regressor,newdata=dataset)
summary(regressor)
source('C:/Users/Asanka/Desktop/Udmy/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 5 - Multiple Linear Regression/Multiple_Linear_Regression/Exdata_preprocessing_template.R')
source('C:/Users/Asanka/Desktop/Udmy/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 5 - Multiple Linear Regression/Multiple_Linear_Regression/Exdata_preprocessing_template.R')
source('C:/Users/Asanka/Desktop/Udmy/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 5 - Multiple Linear Regression/Multiple_Linear_Regression/Exdata_preprocessing_template.R')
library(readr)
X50_Startups <- read_csv("C:/Users/Asanka/Desktop/Udmy/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 5 - Multiple Linear Regression/Multiple_Linear_Regression/50_Startups.csv")
View(X50_Startups)
View(X50_Startups)
View(X50_Startups)
load("C:/Users/Asanka/Desktop/Udmy/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 5 - Multiple Linear Regression/Multiple_Linear_Regression/50_Startups.csv")
source('C:/Users/Asanka/Desktop/Udmy/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 5 - Multiple Linear Regression/Multiple_Linear_Regression/Exdata_preprocessing_template.R')
setwd("C:/Users/Asanka/Desktop/Udmy/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 5 - Multiple Linear Regression/Multiple_Linear_Regression")
source('C:/Users/Asanka/Desktop/Udmy/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 5 - Multiple Linear Regression/Multiple_Linear_Regression/Exdata_preprocessing_template.R')
# Data Preprocessing Template
# Importing the dataset
dataset = read.csv('50_Startups.csv')
# Encoding categorical data //because linear regression needs numbers
dataset$State = factor(dataset$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1, 2, 3))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Profit, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling //- no need replaces by a function we use
#Fitting multiple Linear Regression to the training set
regressor=lm(formula = Profit~. ,data=training_set)#lm(relationship between dependent and independent Variables)
#Since R & D spent is the highly strongly predictor other variables are not much useful
#regressor=lm(formula = Profit~R.D.Spend ,data=training_set)
#predictiing the test set results
y_pred=predict(regressor,newdata=test_set)
#making optimal model using ~ BACKWORD ELIMINATION ~
regressor=lm(formula = Profit~R.D.Spend+Administration+Marketing.Spend+State ,data=training_set)
y_pred=predict(regressor,newdata=dataset)
summary(regressor)
#making optimal model using ~ BACKWORD ELIMINATION ~
regressor=lm(formula = Profit~R.D.Spend+Administration+Marketing.Spend ,data=training_set)#Remove state since p=0.9xx
y_pred=predict(regressor,newdata=dataset)
summary(regressor)
#making optimal model using ~ BACKWORD ELIMINATION ~
regressor=lm(formula = Profit~R.D.Spend+Marketing.Spend,data=training_set)#Remove Administration since p>SL
y_pred=predict(regressor,newdata=dataset)
summary(regressor)
#making optimal model using ~ BACKWORD ELIMINATION ~
regressor=lm(formula = Profit~R.D.Spend,data=training_set)#Remove Marketing.Spend since p>SL
y_pred=predict(regressor,newdata=dataset)
summary(regressor)#making optimal model using ~ BACKWORD ELIMINATION ~
regressor=lm(formula = Profit~R.D.Spend+Marketing.Spend,data=training_set)#Since marketing.Spend have no big difference,keep it
y_pred=predict(regressor,newdata=dataset)
summary(regressor)
setwd("C:/Users/Asanka/Desktop/Udmy/Machine Learning A-Z Template Folder/Part 2 - Regression/Section 8 - Decision Tree Regression/Decision_Tree_Regression")
system("python decision_tree_regression.py")
